<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Reference · NLPModelsTest.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/style.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="NLPModelsTest.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">NLPModelsTest.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../problems/">Problems</a></li><li class="is-active"><a class="tocitem" href>Reference</a><ul class="internal"><li><a class="tocitem" href="#Contents"><span>Contents</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Reference</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/main/docs/src/reference.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Reference"><a class="docs-heading-anchor" href="#Reference">Reference</a><a id="Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Reference" title="Permalink"></a></h1><p>​</p><h2 id="Contents"><a class="docs-heading-anchor" href="#Contents">Contents</a><a id="Contents-1"></a><a class="docs-heading-anchor-permalink" href="#Contents" title="Permalink"></a></h2><p>​</p><ul><li><a href="#Reference">Reference</a></li><li class="no-marker"><ul><li><a href="#Contents">Contents</a></li><li><a href="#Index">Index</a></li></ul></li></ul><p>​</p><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><p>​</p><ul><li><a href="#NLPModelsTest.BROWNDEN"><code>NLPModelsTest.BROWNDEN</code></a></li><li><a href="#NLPModelsTest.HS10"><code>NLPModelsTest.HS10</code></a></li><li><a href="#NLPModelsTest.HS11"><code>NLPModelsTest.HS11</code></a></li><li><a href="#NLPModelsTest.HS13"><code>NLPModelsTest.HS13</code></a></li><li><a href="#NLPModelsTest.HS14"><code>NLPModelsTest.HS14</code></a></li><li><a href="#NLPModelsTest.HS5"><code>NLPModelsTest.HS5</code></a></li><li><a href="#NLPModelsTest.HS6"><code>NLPModelsTest.HS6</code></a></li><li><a href="#NLPModelsTest.LINCON"><code>NLPModelsTest.LINCON</code></a></li><li><a href="#NLPModelsTest.LINSV"><code>NLPModelsTest.LINSV</code></a></li><li><a href="#NLPModelsTest.LLS"><code>NLPModelsTest.LLS</code></a></li><li><a href="#NLPModelsTest.MGH01"><code>NLPModelsTest.MGH01</code></a></li><li><a href="#NLPModelsTest.MGH01Feas"><code>NLPModelsTest.MGH01Feas</code></a></li><li><a href="#NLPModelsTest.NLSHS20"><code>NLPModelsTest.NLSHS20</code></a></li><li><a href="#NLPModelsTest.NLSLC"><code>NLPModelsTest.NLSLC</code></a></li><li><a href="#NLPModelsTest.check_nlp_dimensions-Tuple{Any}"><code>NLPModelsTest.check_nlp_dimensions</code></a></li><li><a href="#NLPModelsTest.check_nls_dimensions-Tuple{Any}"><code>NLPModelsTest.check_nls_dimensions</code></a></li><li><a href="#NLPModelsTest.consistent_nlps-Tuple{Any}"><code>NLPModelsTest.consistent_nlps</code></a></li><li><a href="#NLPModelsTest.consistent_nlss-Tuple{Any}"><code>NLPModelsTest.consistent_nlss</code></a></li><li><a href="#NLPModelsTest.coord_memory_nlp-Tuple{NLPModels.AbstractNLPModel}"><code>NLPModelsTest.coord_memory_nlp</code></a></li><li><a href="#NLPModelsTest.gradient_check-Tuple{NLPModels.AbstractNLPModel}"><code>NLPModelsTest.gradient_check</code></a></li><li><a href="#NLPModelsTest.hessian_check-Tuple{NLPModels.AbstractNLPModel}"><code>NLPModelsTest.hessian_check</code></a></li><li><a href="#NLPModelsTest.hessian_check_from_grad-Tuple{NLPModels.AbstractNLPModel}"><code>NLPModelsTest.hessian_check_from_grad</code></a></li><li><a href="#NLPModelsTest.jacobian_check-Tuple{NLPModels.AbstractNLPModel}"><code>NLPModelsTest.jacobian_check</code></a></li><li><a href="#NLPModelsTest.multiple_precision_nlp-Tuple{Any}"><code>NLPModelsTest.multiple_precision_nlp</code></a></li><li><a href="#NLPModelsTest.multiple_precision_nls-Tuple{Any}"><code>NLPModelsTest.multiple_precision_nls</code></a></li><li><a href="#NLPModelsTest.print_nlp_allocations-Tuple{NLPModels.AbstractNLPModel, Dict}"><code>NLPModelsTest.print_nlp_allocations</code></a></li><li><a href="#NLPModelsTest.test_allocs_nlpmodels-Tuple{NLPModels.AbstractNLPModel}"><code>NLPModelsTest.test_allocs_nlpmodels</code></a></li><li><a href="#NLPModelsTest.test_allocs_nlsmodels-Tuple{NLPModels.AbstractNLSModel}"><code>NLPModelsTest.test_allocs_nlsmodels</code></a></li><li><a href="#NLPModelsTest.test_obj_grad!-Tuple{Any, NLPModels.AbstractNLPModel, Any}"><code>NLPModelsTest.test_obj_grad!</code></a></li><li><a href="#NLPModelsTest.test_zero_allocations-Tuple{NLPModels.AbstractNLPModel}"><code>NLPModelsTest.test_zero_allocations</code></a></li><li><a href="#NLPModelsTest.view_subarray_nlp-Tuple{Any}"><code>NLPModelsTest.view_subarray_nlp</code></a></li><li><a href="#NLPModelsTest.view_subarray_nls-Tuple{Any}"><code>NLPModelsTest.view_subarray_nls</code></a></li></ul><p>​</p><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.BROWNDEN" href="#NLPModelsTest.BROWNDEN"><code>NLPModelsTest.BROWNDEN</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">nlp = BROWNDEN()</code></pre><p><strong>Brown and Dennis function.</strong></p><pre><code class="nohighlight hljs">Source: Problem 16 in
J.J. Moré, B.S. Garbow and K.E. Hillstrom,
&quot;Testing Unconstrained Optimization Software&quot;,
ACM Transactions on Mathematical Software, vol. 7(1), pp. 17-41, 1981

classification SUR2-AN-4-0</code></pre><p class="math-container">\[\min_x \ \sum_{i=1}^{20} \left(\left(x_1 + \tfrac{i}{5} x_2 - e^{i / 5}\right)^2
+ \left(x_3 + \sin(\tfrac{i}{5}) x_4 - \cos(\tfrac{i}{5})\right)^2\right)^2\]</p><p>Starting point: <code>[25.0; 5.0; -5.0; -1.0]</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nlp/problems/brownden.jl#L5-L23">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.HS10" href="#NLPModelsTest.HS10"><code>NLPModelsTest.HS10</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">nlp = HS10()</code></pre><p><strong>Problem 10 in the Hock-Schittkowski suite</strong></p><p class="math-container">\[\begin{aligned}
\min \quad &amp; x_1 - x_2 \\
\text{s. to} \quad &amp; -3x_1^2 + 2x_1 x_2 - x_2^2 + 1 \geq 0
\end{aligned}\]</p><p>Starting point: <code>[-10; 10]</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nlp/problems/hs10.jl#L3-L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.HS11" href="#NLPModelsTest.HS11"><code>NLPModelsTest.HS11</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">nlp = HS11()</code></pre><p><strong>Problem 11 in the Hock-Schittkowski suite</strong></p><p class="math-container">\[\begin{aligned}
\min \quad &amp; (x_1 - 5)^2 + x_2^2 - 25 \\
\text{s. to} \quad &amp; 0 \leq -x_1^2 + x_2
\end{aligned}\]</p><p>Starting point: <code>[-4.9; 0.1]</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nlp/problems/hs11.jl#L3-L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.HS13" href="#NLPModelsTest.HS13"><code>NLPModelsTest.HS13</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">nlp = HS13()</code></pre><p><strong>Problem 13 in the Hock-Schittkowski suite</strong></p><p class="math-container">\[\begin{aligned}
\min \quad &amp; (x_1 - 2)^2 + x_2^2 \\
\text{s. to} \quad &amp; (1 - x_1)^3 - x_2 \geq 0
\quad &amp; 0 \leq x_1 \\
&amp; 0 \leq x_2
\end{aligned}\]</p><p>Starting point: <code>[-2; -2]</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nlp/problems/hs13.jl#L3-L18">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.HS14" href="#NLPModelsTest.HS14"><code>NLPModelsTest.HS14</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">nlp = HS14()</code></pre><p><strong>Problem 14 in the Hock-Schittkowski suite</strong></p><p class="math-container">\[\begin{aligned}
\min \quad &amp; (x_1 - 2)^2 + (x_2 - 1)^2 \\
\text{s. to} \quad &amp; x_1 - 2x_2 = -1 \\
&amp; -\tfrac{1}{4} x_1^2 - x_2^2 + 1 \geq 0
\end{aligned}\]</p><p>Starting point: <code>[2; 2]</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nlp/problems/hs14.jl#L3-L17">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.HS5" href="#NLPModelsTest.HS5"><code>NLPModelsTest.HS5</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">nlp = HS5()</code></pre><p><strong>Problem 5 in the Hock-Schittkowski suite</strong></p><p class="math-container">\[\begin{aligned}
\min \quad &amp; \sin(x_1 + x_2) + (x_1 - x_2)^2 - \tfrac{3}{2}x_1 + \tfrac{5}{2}x_2 + 1 \\
\text{s. to} \quad &amp; -1.5 \leq x_1 \leq 4 \\
&amp; -3 \leq x_2 \leq 3
\end{aligned}\]</p><p>Starting point: <code>[0.0; 0.0]</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nlp/problems/hs5.jl#L3-L17">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.HS6" href="#NLPModelsTest.HS6"><code>NLPModelsTest.HS6</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">nlp = HS6()</code></pre><p><strong>Problem 6 in the Hock-Schittkowski suite</strong></p><p class="math-container">\[\begin{aligned}
\min \quad &amp; (1 - x_1)^2 \\
\text{s. to} \quad &amp; 10 (x_2 - x_1^2) = 0
\end{aligned}\]</p><p>Starting point: <code>[-1.2; 1.0]</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nlp/problems/hs6.jl#L3-L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.LINCON" href="#NLPModelsTest.LINCON"><code>NLPModelsTest.LINCON</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">nlp = LINCON()</code></pre><p><strong>Linearly constrained problem</strong></p><p class="math-container">\[\begin{aligned}
\min \quad &amp; (i + x_i^4) \\
\text{s. to} \quad &amp; x_{15} = 0 \\
&amp; x_{10} + 2x_{11} + 3x_{12} \geq 1 \\
&amp; x_{13} - x_{14} \leq 16 \\
&amp; -11 \leq 5x_8 - 6x_9 \leq 9 \\
&amp; -2x_7 = -1 \\
&amp; 4x_6 = 1 \\
&amp; x_1 + 2x_2 \geq -5 \\
&amp; 3x_1 + 4x_2 \geq -6 \\
&amp; 9x_3 \leq 1 \\
&amp; 12x_4 \leq 2 \\
&amp; 15x_5 \leq 3
\end{aligned}\]</p><p>Starting point: <code>zeros(15)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nlp/problems/lincon.jl#L3-L26">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.LINSV" href="#NLPModelsTest.LINSV"><code>NLPModelsTest.LINSV</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">nlp = LINSV()</code></pre><p><strong>Linear problem</strong></p><p class="math-container">\[\begin{aligned}
\min \quad &amp; x_1 \\
\text{s. to} \quad &amp; x_1 + x_2 \geq 3 \\
&amp; x_2 \geq 1
\end{aligned}\]</p><p>Starting point: <code>[0; 0]</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nlp/problems/linsv.jl#L3-L17">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.LLS" href="#NLPModelsTest.LLS"><code>NLPModelsTest.LLS</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">nls = LLS()</code></pre><p><strong>Linear least squares</strong></p><p class="math-container">\[\begin{aligned}
\min \quad &amp; \tfrac{1}{2}\| F(x) \|^2 \\
\text{s. to} \quad &amp; x_1 + x_2 \geq 0
\end{aligned}\]</p><p>where</p><p class="math-container">\[F(x) = \begin{bmatrix}
x_1 - x_2 \\
x_1 + x_2 - 2 \\
x_2 - 2
\end{bmatrix}.\]</p><p>Starting point: <code>[0; 0]</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nls/problems/lls.jl#L3-L24">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.MGH01" href="#NLPModelsTest.MGH01"><code>NLPModelsTest.MGH01</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">nls = MGH01()</code></pre><p><strong>Rosenbrock function in nonlinear least squares format</strong></p><pre><code class="nohighlight hljs">Source: Problem 1 in
J.J. Moré, B.S. Garbow and K.E. Hillstrom,
&quot;Testing Unconstrained Optimization Software&quot;,
ACM Transactions on Mathematical Software, vol. 7(1), pp. 17-41, 1981</code></pre><p class="math-container">\[\begin{aligned}
\min \quad &amp; \tfrac{1}{2}\| F(x) \|^2
\end{aligned}\]</p><p>where</p><p class="math-container">\[F(x) = \begin{bmatrix}
1 - x_1 \\
10 (x_2 - x_1^2)
\end{bmatrix}.\]</p><p>Starting point: <code>[-1.2; 1]</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nls/problems/mgh01.jl#L5-L29">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.MGH01Feas" href="#NLPModelsTest.MGH01Feas"><code>NLPModelsTest.MGH01Feas</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">nlp = MGH01Feas()</code></pre><p><strong>Rosenbrock function in feasibility format</strong></p><pre><code class="nohighlight hljs">Source: Problem 1 in
J.J. Moré, B.S. Garbow and K.E. Hillstrom,
&quot;Testing Unconstrained Optimization Software&quot;,
ACM Transactions on Mathematical Software, vol. 7(1), pp. 17-41, 1981</code></pre><p class="math-container">\[\begin{aligned}
\min \quad &amp; 0 \\
\text{s. to} \quad &amp; x_1 = 1 \\
&amp; 10 (x_2 - x_1^2) = 0.
\end{aligned}\]</p><p>Starting point: <code>[-1.2; 1]</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nlp/problems/mgh01feas.jl#L3-L22">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.NLSHS20" href="#NLPModelsTest.NLSHS20"><code>NLPModelsTest.NLSHS20</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">nls = NLSH20()</code></pre><p><strong>Problem 20 in the Hock-Schittkowski suite in nonlinear least squares format</strong></p><p class="math-container">\[\begin{aligned}
\min \quad &amp; \tfrac{1}{2}\| F(x) \|^2 \\
\text{s. to} \quad &amp; x_1 + x_2^2 \geq 0 \\
&amp; x_1^2 + x_2 \geq 0 \\
&amp; x_1^2 + x_2^2 -1 \geq 0 \\
&amp; -0.5 \leq x_1 \leq 0.5
\end{aligned}\]</p><p>where</p><p class="math-container">\[F(x) = \begin{bmatrix}
1 - x_1 \\
10 (x_2 - x_1^2)
\end{bmatrix}.\]</p><p>Starting point: <code>[-2; 1]</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nls/problems/nlshs20.jl#L3-L26">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.NLSLC" href="#NLPModelsTest.NLSLC"><code>NLPModelsTest.NLSLC</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">nls = NLSLC()</code></pre><p><strong>Linearly constrained nonlinear least squares problem</strong></p><p class="math-container">\[\begin{aligned}
\min \quad &amp; \tfrac{1}{2}\| F(x) \|^2 \\
\text{s. to} \quad &amp; x_{15} = 0 \\
&amp; x_{10} + 2x_{11} + 3x_{12} \geq 1 \\
&amp; x_{13} - x_{14} \leq 16 \\
&amp; -11 \leq 5x_8 - 6x_9 \leq 9 \\
&amp; -2x_7 = -1 \\
&amp; 4x_6 = 1 \\
&amp; x_1 + 2x_2 \geq -5 \\
&amp; 3x_1 + 4x_2 \geq -6 \\
&amp; 9x_3 \leq 1 \\
&amp; 12x_4 \leq 2 \\
&amp; 15x_5 \leq 3
\end{aligned}\]</p><p>where</p><p class="math-container">\[F(x) = \begin{bmatrix}
x_1^2 - 1 \\
x_2^2 - 2^2 \\
\vdots \\
x_{15}^2 - 15^2
\end{bmatrix}\]</p><p>Starting point: <code>zeros(15)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nls/problems/nlslc.jl#L3-L35">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.check_nlp_dimensions-Tuple{Any}" href="#NLPModelsTest.check_nlp_dimensions-Tuple{Any}"><code>NLPModelsTest.check_nlp_dimensions</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">check_nlp_dimensions(nlp; exclude = [ghjvprod])</code></pre><p>Make sure NLP API functions will throw DimensionError if the inputs are not the correct dimension. To make this assertion in your code use</p><pre><code class="nohighlight hljs">@lencheck size input [more inputs separated by spaces]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nlp/check-dimensions.jl#L3-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.check_nls_dimensions-Tuple{Any}" href="#NLPModelsTest.check_nls_dimensions-Tuple{Any}"><code>NLPModelsTest.check_nls_dimensions</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">check_nls_dimensions(nlp; exclude = [])</code></pre><p>Make sure NLS API functions will throw DimensionError if the inputs are not the correct dimension. To make this assertion in your code use</p><pre><code class="nohighlight hljs">@lencheck size input [more inputs separated by spaces]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nls/check-dimensions.jl#L3-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.consistent_nlps-Tuple{Any}" href="#NLPModelsTest.consistent_nlps-Tuple{Any}"><code>NLPModelsTest.consistent_nlps</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">consistent_nlps(nlps; exclude=[], rtol=1e-8)</code></pre><p>Check that the all <code>nlp</code>s of the vector <code>nlps</code> are consistent, in the sense that</p><ul><li>Their counters are the same.</li><li>Their <code>meta</code> information is the same.</li><li>The API functions return the same output given the same input.</li></ul><p>In other words, if you create two models of the same problem, they should be consistent.</p><p>The keyword <code>exclude</code> can be used to pass functions to be ignored, if some of the models don&#39;t implement that function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nlp/consistency.jl#L3-L14">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.consistent_nlss-Tuple{Any}" href="#NLPModelsTest.consistent_nlss-Tuple{Any}"><code>NLPModelsTest.consistent_nlss</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">consistent_nlss(nlps; exclude=[hess, hprod, hess_coord])</code></pre><p>Check that the all <code>nls</code>s of the vector <code>nlss</code> are consistent, in the sense that</p><ul><li>Their counters are the same.</li><li>Their <code>meta</code> information is the same.</li><li>The API functions return the same output given the same input.</li></ul><p>In other words, if you create two models of the same problem, they should be consistent.</p><p>By default, the functions <code>hess</code>, <code>hprod</code> and <code>hess_coord</code> (and therefore associated functions) are excluded from this check, since some models don&#39;t implement them.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nls/consistency.jl#L5-L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.coord_memory_nlp-Tuple{NLPModels.AbstractNLPModel}" href="#NLPModelsTest.coord_memory_nlp-Tuple{NLPModels.AbstractNLPModel}"><code>NLPModelsTest.coord_memory_nlp</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">coord_memory_nlp(nlp; exclude = [])</code></pre><p>Check that the allocated memory for in place coord methods is sufficiently smaller than their allocating counter parts.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nlp/coord-memory.jl#L3-L8">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.gradient_check-Tuple{NLPModels.AbstractNLPModel}" href="#NLPModelsTest.gradient_check-Tuple{NLPModels.AbstractNLPModel}"><code>NLPModelsTest.gradient_check</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">gradient_check(nlp; x=nlp.meta.x0, atol=1e-6, rtol=1e-4)</code></pre><p>Check the first derivatives of the objective at <code>x</code> against centered finite differences.</p><p>This function returns a dictionary indexed by components of the gradient for which the relative error exceeds <code>rtol</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/dercheck.jl#L7-L15">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.hessian_check-Tuple{NLPModels.AbstractNLPModel}" href="#NLPModelsTest.hessian_check-Tuple{NLPModels.AbstractNLPModel}"><code>NLPModelsTest.hessian_check</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">hessian_check(nlp; x=nlp.meta.x0, atol=1e-6, rtol=1e-4, sgn=1)</code></pre><p>Check the second derivatives of the objective and each constraints at <code>x</code> against centered finite differences. This check does not rely on exactness of the first derivatives, only on objective and constraint values.</p><p>The <code>sgn</code> arguments refers to the formulation of the Lagrangian in the problem. It should have a positive value if the Lagrangian is formulated as</p><p class="math-container">\[L(x,y) = f(x) + \sum_j yⱼ cⱼ(x),\]</p><p>and a negative value if the Lagrangian is formulated as</p><p class="math-container">\[L(x,y) = f(x) - \sum_j yⱼ cⱼ(x).\]</p><p>Only the sign of <code>sgn</code> is important.</p><p>This function returns a dictionary indexed by functions. The 0-th function is the objective while the k-th function (for k &gt; 0) is the k-th constraint. The values of the dictionary are dictionaries indexed by tuples (i, j) such that the relative error in the second derivative ∂²fₖ/∂xᵢ∂xⱼ exceeds <code>rtol</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/dercheck.jl#L88-L110">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.hessian_check_from_grad-Tuple{NLPModels.AbstractNLPModel}" href="#NLPModelsTest.hessian_check_from_grad-Tuple{NLPModels.AbstractNLPModel}"><code>NLPModelsTest.hessian_check_from_grad</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">hessian_check_from_grad(nlp; x=nlp.meta.x0, atol=1e-6, rtol=1e-4, sgn=1)</code></pre><p>Check the second derivatives of the objective and each constraints at <code>x</code> against centered finite differences. This check assumes exactness of the first derivatives.</p><p>The <code>sgn</code> arguments refers to the formulation of the Lagrangian in the problem. It should have a positive value if the Lagrangian is formulated as</p><p class="math-container">\[L(x,y) = f(x) + \sum_j yⱼ cⱼ(x),\]</p><p>and a negative value if the Lagrangian is formulated as</p><p class="math-container">\[L(x,y) = f(x) - \sum_j yⱼ cⱼ(x).\]</p><p>Only the sign of <code>sgn</code> is important.</p><p>This function returns a dictionary indexed by functions. The 0-th function is the objective while the k-th function (for k &gt; 0) is the k-th constraint. The values of the dictionary are dictionaries indexed by tuples (i, j) such that the relative error in the second derivative ∂²fₖ/∂xᵢ∂xⱼ exceeds <code>rtol</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/dercheck.jl#L181-L203">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.jacobian_check-Tuple{NLPModels.AbstractNLPModel}" href="#NLPModelsTest.jacobian_check-Tuple{NLPModels.AbstractNLPModel}"><code>NLPModelsTest.jacobian_check</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">jacobian_check(nlp; x=nlp.meta.x0, atol=1e-6, rtol=1e-4)</code></pre><p>Check the first derivatives of the constraints at <code>x</code> against centered finite differences.</p><p>This function returns a dictionary indexed by (j, i) tuples such that the relative error in the <code>i</code>-th partial derivative of the <code>j</code>-th constraint exceeds <code>rtol</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/dercheck.jl#L42-L51">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.multiple_precision_nlp-Tuple{Any}" href="#NLPModelsTest.multiple_precision_nlp-Tuple{Any}"><code>NLPModelsTest.multiple_precision_nlp</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">multiple_precision_nlp(nlp_from_T; precisions=[...], exclude = [ghjvprod])</code></pre><p>Check that the NLP API functions output type are the same as the input. In other words, make sure that the model handles multiple precisions.</p><p>The input <code>nlp_from_T</code> is a function that returns an <code>nlp</code> from a type <code>T</code>. The array <code>precisions</code> are the tested floating point types. Defaults to <code>[Float16, Float32, Float64, BigFloat]</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nlp/multiple-precision.jl#L12-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.multiple_precision_nls-Tuple{Any}" href="#NLPModelsTest.multiple_precision_nls-Tuple{Any}"><code>NLPModelsTest.multiple_precision_nls</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">multiple_precision_nls(nls_from_T; precisions=[...], exclude = [])</code></pre><p>Check that the NLS API functions output type are the same as the input. In other words, make sure that the model handles multiple precisions.</p><p>The input <code>nls_from_T</code> is a function that returns an <code>nls</code> from a type <code>T</code>. The array <code>precisions</code> are the tested floating point types. Defaults to <code>[Float16, Float32, Float64, BigFloat]</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nls/multiple-precision.jl#L12-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.print_nlp_allocations-Tuple{NLPModels.AbstractNLPModel, Dict}" href="#NLPModelsTest.print_nlp_allocations-Tuple{NLPModels.AbstractNLPModel, Dict}"><code>NLPModelsTest.print_nlp_allocations</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">print_nlp_allocations([io::IO = stdout], nlp::AbstractNLPModel, table::Dict; only_nonzeros::Bool = false)
print_nlp_allocations([io::IO = stdout], nlp::AbstractNLPModel; kwargs...)</code></pre><p>Print in a convenient way the result of <code>test_allocs_nlpmodels(nlp)</code>.</p><p>The keyword arguments may contain:</p><ul><li><code>only_nonzeros::Bool</code>: shows only non-zeros if true.</li><li><code>linear_api::Bool</code>: checks the functions specific to linear and nonlinear constraints, see <a href="#NLPModelsTest.test_allocs_nlpmodels-Tuple{NLPModels.AbstractNLPModel}"><code>test_allocs_nlpmodels</code></a>.</li><li><code>exclude</code> takes a Array of Function to be excluded from the tests, see <a href="#NLPModelsTest.test_allocs_nlpmodels-Tuple{NLPModels.AbstractNLPModel}"><code>test_allocs_nlpmodels</code></a>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/allocs_model.jl#L330-L340">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.test_allocs_nlpmodels-Tuple{NLPModels.AbstractNLPModel}" href="#NLPModelsTest.test_allocs_nlpmodels-Tuple{NLPModels.AbstractNLPModel}"><code>NLPModelsTest.test_allocs_nlpmodels</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">test_allocs_nlpmodels(nlp::AbstractNLPModel; linear_api = false, exclude = [])</code></pre><p>Returns a <code>Dict</code> containing allocations of the in-place functions of NLPModel API.</p><p>The keyword <code>exclude</code> takes a Array of Function to be excluded from the tests. Use <code>hess</code> (resp. <code>jac</code>) to exclude <code>hess_coord</code> and <code>hess_structure</code> (resp. <code>jac_coord</code> and <code>jac_structure</code>). Setting <code>linear_api</code> to <code>true</code> will also checks the functions specific to linear and nonlinear constraints.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/allocs_model.jl#L3-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.test_allocs_nlsmodels-Tuple{NLPModels.AbstractNLSModel}" href="#NLPModelsTest.test_allocs_nlsmodels-Tuple{NLPModels.AbstractNLSModel}"><code>NLPModelsTest.test_allocs_nlsmodels</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">test_allocs_nlsmodels(nlp::AbstractNLSModel; exclude = [])</code></pre><p>Returns a <code>Dict</code> containing allocations of the in-place functions specialized to nonlinear least squares of NLPModel API.</p><p>The keyword <code>exclude</code> takes a Array of Function to be excluded from the tests.  Use <code>hess_residual</code> (resp. <code>jac_residual</code>) to exclude <code>hess_residual_coord</code> and <code>hess_residual_structure</code> (resp. <code>jac_residual_coord</code> and <code>jac_residual_structure</code>). The hessian-vector product is tested for all the component of the residual function, so exclude <code>hprod_residual</code> and <code>hess_op_residual</code> if you want to avoid this.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/allocs_model.jl#L225-L233">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.test_obj_grad!-Tuple{Any, NLPModels.AbstractNLPModel, Any}" href="#NLPModelsTest.test_obj_grad!-Tuple{Any, NLPModels.AbstractNLPModel, Any}"><code>NLPModelsTest.test_obj_grad!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">test_obj_grad!(nlp_allocations, nlp::AbstractNLPModel, exclude)</code></pre><p>Update <code>nlp_allocations</code> with allocations of the in-place <code>obj</code> and <code>grad</code> functions.</p><p>For <code>AbstractNLSModel</code>, this uses <code>obj</code> and <code>grad</code> with pre-allocated residual.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/allocs_model.jl#L186-L192">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.test_zero_allocations-Tuple{NLPModels.AbstractNLPModel}" href="#NLPModelsTest.test_zero_allocations-Tuple{NLPModels.AbstractNLPModel}"><code>NLPModelsTest.test_zero_allocations</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">test_zero_allocations(table::Dict, name::String = &quot;Generic&quot;)
test_zero_allocations(nlp::AbstractNLPModel; kwargs...)</code></pre><p>Test wether the result of <code>test_allocs_nlpmodels(nlp)</code> and <code>test_allocs_nlsmodels(nlp)</code> is 0.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/allocs_model.jl#L392-L397">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.view_subarray_nlp-Tuple{Any}" href="#NLPModelsTest.view_subarray_nlp-Tuple{Any}"><code>NLPModelsTest.view_subarray_nlp</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">view_subarray_nlp(nlp; exclude = [])</code></pre><p>Check that the API work with views, and that the results is correct.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nlp/view-subarray.jl#L3-L7">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModelsTest.view_subarray_nls-Tuple{Any}" href="#NLPModelsTest.view_subarray_nls-Tuple{Any}"><code>NLPModelsTest.view_subarray_nls</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">view_subarray_nls(nls; exclude = [])</code></pre><p>Check that the API work with views, and that the results is correct.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaSmoothOptimizers/NLPModelsTest.jl/blob/65fa66da79d8fae72bf33a2efa43d8387095524b/src/nls/view-subarray.jl#L3-L7">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../problems/">« Problems</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Monday 12 June 2023 11:41">Monday 12 June 2023</span>. Using Julia version 1.9.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
